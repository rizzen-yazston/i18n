= i18n_lexer
Rizzen Yazston
:BufferProvider: https://docs.rs/icu_provider/latest/icu_provider/buf/trait.BufferProvider.html
:CLDR: https://cldr.unicode.org/
:ICU4X: https://github.com/unicode-org/icu4x
:Unicode_Consortium: https://home.unicode.org/

String lexer and resultant tokens.

The `Lexer` is initialised using a data provider {BufferProvider}[`BufferProvider`] to an {Unicode_Consortium}[Unicode Consortium] {CLDR}[CLDR] data repository, usually it is just a local copy of the CLDR in the application's data directory. Once the `Lexer` has been initialised it may be used to tokenise strings, without needing to re-initialising the `Lexer` before use. Consult the {ICU4X}[ICU4X] website for instructions on generating a suitable data repository for the application, by leaving out data that is not used by the application. 

Strings are tokenised using the method `tokenise()` taking string slice and a vector containing grammar syntax characters.

== Cargo.toml

```
[dependencies]
i18n_lexer-rizzen-yazston = "0.2.0"

[dependencies.icu_provider]
version = "1.0.0"
# Needed for BufferProvider
features = [ "serde", "deserialize_bincode_1" ]
```

== Examples

```
use icu_provider::prelude::*;
use std::rc::Rc;
use i18n_lexer::{Token, TokenType, Lexer};
use icu_testdata::buffer;

let buffer_provider = Box::new( buffer() );
let mut lexer = Lexer::try_new( buffer_provider ).expect( "Failed to initialise lexer." );
let tokens = lexer.tokenise(
    // World Map (U+1F5FA) is encoded in four bytes in UTF-8.
    "String contains a {placeholder}.", vec![ '{', '}' ]
);
let mut grammar = 0;
assert_eq!( tokens.iter().count(), 10, "Supposed to be a total of 10 tokens." );
for token in tokens.iter() {
    if token.token_type == TokenType::Grammar {
        grammar += 1;
    }
}
assert_eq!( grammar, 2, "Supposed to be 2 grammar tokens." );
```
